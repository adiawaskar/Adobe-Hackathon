# Adobe Hackathon - Challenge 1B  
## ğŸ§  Approach Explanation for Persona-Driven Document Intelligence

## ğŸ§© Overview
This project implements an intelligent, multilingual PDF document processing pipeline that extracts and ranks relevant sections from unstructured documents based on a userâ€™s **persona** and **job description**. The system is built to be domain-agnostic, scalable, and designed for efficient and fast processing in recruitment, personalization, and document analysis.

---

## âš™ï¸ Methodology

### 1. ğŸ“¥ Document Ingestion and Preprocessing
All PDFs placed in the `/input` directory are automatically processed. The system uses **LangChainâ€™s PyPDFLoader** to extract raw text from each document.

To maintain semantic coherence, the text is split using `RecursiveCharacterTextSplitter` with:
- `chunk_size = 1000`
- `chunk_overlap = 200`  
This ensures boundary-sensitive content (e.g., long paragraphs or headings) is preserved across splits.

---

### 2. ğŸŒ Semantic Embedding and Retrieval
Each chunk is embedded using the **`paraphrase-multilingual-MiniLM-L12-v2`** model from HuggingFace. This supports over 50 languages, enabling robust **language-agnostic** processing.

Embeddings are stored in a **Chroma vector store**, enabling fast semantic similarity retrieval. The **query vector** is created by combining the **persona** and **job description**, representing the user's information need.

---

### 3. ğŸ¯ Relevance-Based Chunk Selection
The system retrieves the top `k` most relevant chunks based on cosine similarity. Duplicates and near-duplicates are filtered out to ensure diversity in extracted content.

---

### 4. ğŸ§¹ Heading Extraction and Structuring
For each selected chunk:
- A **heuristic-based heading** is derived from the first non-empty line (stripped and capitalized).
- The chunk body is cleaned of redundant characters and formatting issues.
This provides a readable and organized final structure.

---

### 5. ğŸ“¤ Output Generation
The final result is exported as a structured JSON file containing:
- ğŸ“Œ **Metadata**: Input filenames, persona, job role, and timestamp
- ğŸ§© **Extracted Sections**: Headings and cleaned, relevant content
- ğŸ§  **Subsection Analysis**: Subsection-wise breakdowns and insight extraction

The output is fully compatible with downstream applications such as NLP pipelines, custom dashboards, or LLM-based retrieval systems.

---

## ğŸŒŸ Key Technical Highlights

- âœ… **Multilingual Support**: Supports global datasets across languages
- âœ… **Semantic Search > Keyword Matching**
- âœ… **Domain-Agnostic Architecture**
- âœ… **Fast Local Inference** using HuggingFace + Chroma
- âœ… **Modular & Lightweight Codebase**
- âœ… **Structured JSON Output** for clean integration

---

## ğŸ§  Summary
This pipeline transforms unstructured PDFs into structured, persona-relevant summaries. It combines **semantic intelligence**, **multilingual embedding**, and **intuitive document structuring** to deliver precise and useful insights. Its versatility makes it applicable across domains and industries â€” from tech hiring to academic screening and knowledge mining. ğŸ§¾ğŸ”
